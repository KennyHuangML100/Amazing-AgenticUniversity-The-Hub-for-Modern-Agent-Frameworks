{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# VectorStoreRetrieverMemory\n",
    "## 概覽\n",
    "\n",
    "```VectorStoreRetrieverMemory``` 將記憶儲存在向量資料庫中，每次被調用時會查詢排名前 K 的「相關」文件。  \n",
    "這與其他大多數記憶類別不同，因為它不會明確追蹤對話的時間順序。\n",
    "\n",
    "在本教學中，我們將透過模擬面試場景，探索 ```VectorStoreRetrieverMemory``` 的實務應用。透過此範例，我們將看到 ```VectorStoreRetrieverMemory``` 是如何根據語意相關性來搜尋資訊，而非依照對話的時間順序。\n",
    "\n",
    "### 目錄\n",
    "\n",
    "- [概覽](#overview)\n",
    "- [環境設置](#environment-setup)\n",
    "- [初始化向量資料庫](#initializing-the-vector-store)\n",
    "- [儲存面試對話](#saving-interview-conversations)\n",
    "- [檢索相關對話](#retrieving-relevant-conversations)\n",
    "\n",
    "### 參考資料\n",
    "\n",
    "- [LangChain Python API 參考 > langchain: 0.3.13 > memory > VectorStoreRetrieverMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.vectorstore.VectorStoreRetrieverMemory.html)\n",
    "- [Faiss](https://github.com/facebookresearch/faiss)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21943adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ec196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\"langchain_community\", \"langchain_openai\", \"langchain_core\", \"faiss-cpu\"],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9065ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"VectorStoreRetrieverMemory\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a9ae0",
   "metadata": {},
   "source": [
    "You can alternatively set ```OPENAI_API_KEY``` in ```.env``` file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set ```OPENAI_API_KEY``` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f99b5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {},
   "source": [
    "## Initializing the Vector Store\n",
    "\n",
    "Next, we'll set up our vector store using FAISS. FAISS is an efficient similarity search library that will help us store and retrieve conversation embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cb77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create FAISS index\n",
    "embedding_size = 1536  # Size for OpenAI embeddings\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be1e5e",
   "metadata": {},
   "source": [
    "This setup creates an in-memory vector store that will maintain our conversation embeddings for quick similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159d1bd",
   "metadata": {},
   "source": [
    "## 儲存面試對話\n",
    "\n",
    "接下來，我們將建立記憶系統，並填入範例面試對話。\n",
    "\n",
    "請注意，設定 ```k=1``` 可確保只回傳最相關的一則對話。（在實際應用中，你可能會希望增加此數值，以提供更多上下文。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223559c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/3pdyzl995m5_37d6rr9vfbh00000gn/T/ipykernel_31365/1922969020.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=retriever)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# We set k=1 to show that vector lookups still can return semantically relevant information\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "#請winsruf幫我把所有的md英文或是英文的prompt都改成中文\n",
    "\n",
    "# Save arbitrary conversations\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"哈囉, 謝謝你來面試, 請介紹自己\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"你好, 我是位專注於開發的開發者, 我主修計算機科學, 在大學時主要使用 Java 和 Python, 最近我參與了一個 Web 開發專案, 在這個專案中我學習了如何開發服務以供實際使用者使用。\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"你的角色在專案中是什麼?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"我的角色是後端開發者, 我負責處理使用者資料, 開發服務器邏輯, 實現 RESTful API 以供前端使用, 我也參與了資料庫設計\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"你有什麼困難在小組專案中, 你是如何解決的?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"我們在專案初期有些溝通問題。為了解決這個問題, 我們的團隊定期舉行會議, 分享每個成員的進度。此外, 當問題出現時, 我們積極分享意見並共同努力找到合理的解決方案。\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"你認為自己作為開發者的強項是什麼?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"我的強項是快速學習能力和問題解決能力。我能夠快速掌握新的技術和工具，當面臨複雜問題時，我能夠提出創意解決方案。此外，我非常重視團隊合作，認為與同事合作很重要。\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9273c9e",
   "metadata": {},
   "source": [
    "## Retrieving Relevant Conversations\n",
    "\n",
    "讓我們看看系統如何根據查詢检索相關信息:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e26edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What was the interviewee's major?\n",
      "human: Hello, thank you for coming to the interview today. Please introduce yourself.\n",
      "ai: Hello. I'm a junior developer who majored in Computer Science. In college, I mainly used Java and Python, and recently, I participated in a web development project where I gained experience developing services for real users.\n"
     ]
    }
   ],
   "source": [
    "# Query about educational background\n",
    "print(\"Query: hat was the interviewee's major?\")\n",
    "print(\n",
    "    memory.load_memory_variables({\"prompt\": \"What was the interviewee's major?\"})[\n",
    "        \"history\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5ccd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What was the interviewee's role in the project?\n",
      "human: What was your role in the project?\n",
      "ai: My role was as a backend developer. I was responsible for processing user data and developing server logic, implementing RESTful APIs for communication with the frontend. I also participated in database design.\n"
     ]
    }
   ],
   "source": [
    "# Query about project experience\n",
    "print(\"Query: What was the interviewee's role in the project?\")\n",
    "print(\n",
    "    memory.load_memory_variables(\n",
    "        {\"human\": \"What was the interviewee's role in the project?\"}\n",
    "    )[\"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4422fb",
   "metadata": {},
   "source": [
    "這種方法在建構需要根據過去對話上下文進行參考的系統時特別有價值，例如客服機器人、教育助理，或任何需要維持具上下文意識對話歷史的應用場景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4503eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-ZA2wmMtu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
