{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationTokenBufferMemory\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/05-Memory/03-ConversationTokenBufferMemory.ipynb)[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/05-Memory/03-ConversationTokenBufferMemory.ipynb)\n",
    "\n",
    "## 概覽\n",
    "\n",
    "```ConversationTokenBufferMemory``` 在緩衝記憶體中存儲最近的對話歷史，並根據**token長度**而非對話次數來決定何時清除對話內容。\n",
    "\n",
    "主要參數：\n",
    "- ```max_token_limit```：設定存儲對話內容的最大令牌長度\n",
    "- ```return_messages```：為 True 時，以聊天格式返回訊息。為 False 時，返回字串\n",
    "- ```human_prefix```：在人類訊息前添加的前綴（預設：\"Human\"）\n",
    "- ```ai_prefix```：在 AI 訊息前添加的前綴（預設：\"AI\"）\n",
    "\n",
    "## 目錄\n",
    "\n",
    "- [概覽](#概覽)\n",
    "- [環境設定](#環境設定)\n",
    "- [將最大令牌長度限制為 50](#將最大令牌長度限制為-50)\n",
    "- [將最大令牌長度設定為 150](#將最大令牌長度設定為-150)\n",
    "\n",
    "## 參考資料\n",
    "\n",
    "- [LangChain Python API Reference > langchain: 0.3.13 > memory > ConversationTokenBufferMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.token_buffer.ConversationTokenBufferMemory.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain-anthropic\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"ConversationTokenBufferMemory\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set ```OPENAI_API_KEY``` in ```.env``` file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set ```OPENAI_API_KEY``` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將最大令牌長度限制為 50\n",
    "\n",
    "本節演示如何將對話記憶體限制為 50 個令牌\n",
    "\n",
    "**解釋：**\n",
    "\n",
    "這個部分主要是要展示當我們設定 `max_token_limit=50` 時，`ConversationTokenBufferMemory` 會如何運作。當對話歷史累積的令牌數量超過 50 個時，系統會自動刪除最舊的對話內容，只保留最新的對話，確保總令牌數不超過設定的限制。這種機制有助於：\n",
    "\n",
    "1. **控制記憶體使用量**：避免對話歷史無限增長\n",
    "2. **符合模型限制**：確保不超過語言模型的上下文窗口\n",
    "3. **維持對話連貫性**：保留最相關的近期對話內容\n",
    "4. **節省計算成本**：減少需要處理的令牌數量\n",
    "\n",
    "這種基於令牌長度的管理方式比單純計算對話輪次更精確，因為不同的訊息可能包含不同數量的令牌。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/lrydr5_50zx8thkmv_czrbzc0000gn/T/ipykernel_59195/361976439.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Create LLM model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Configure memory\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    return_messages=True,  # Limit maximum token length to 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add arbitrary conversations\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"Hello, I recently purchased a machine tool from your company. Could you tell me how to install it?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"Hello! Thank you for your purchase. Could you please tell me the machine model number?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"Yes, the model number is XG-200.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Thank you. I'll help you with the installation guide for the XG-200 model. First, please check the power supply status at the installation site. The machine requires 220V power.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"I've checked the power. What's the next step?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Good. Next, please place the machine on a flat and stable surface. Then, proceed with cable connections according to the provided user manual.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"How do I make the connections?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Please refer to page 5 of the manual. There are detailed instructions for cable connections. If you have any difficulties with this process, I'll be happy to help further.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"What should I do after the installation is complete?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Once the installation is complete, please turn on the power and perform the initial operation test. The test procedure is explained on page 10 of the manual. If there are any issues with the machine or if you need additional support, please don't hesitate to contact us.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"Thank you, this has been very helpful!\"},\n",
    "    outputs={\n",
    "        \"ai\": \"We're always ready to help. If you have any additional questions or need support, please feel free to ask. Have a great day!\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Thank you, this has been very helpful!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"We're always ready to help. If you have any additional questions or need support, please feel free to ask. Have a great day!\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the conversation history\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Maximum Token Length to 150\n",
    "\n",
    "Let's check how the conversation is stored when we set the maximum token length to **150**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory configuration\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True,  # Limit maximum token length to 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add arbitrary conversations\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"Hello, I recently purchased a machine tool from your company. Could you tell me how to install it?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"Hello! Thank you for your purchase. Could you please tell me the machine model number?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"Yes, the model number is XG-200.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Thank you. I'll help you with the installation guide for the XG-200 model. First, please check the power supply status at the installation site. The machine requires 220V power.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"I've checked the power. What's the next step?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Good. Next, please place the machine on a flat and stable surface. Then, proceed with cable connections according to the provided user manual.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"How do I make the connections?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Please refer to page 5 of the manual. There are detailed instructions for cable connections. If you have any difficulties with this process, I'll be happy to help further.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"What should I do after the installation is complete?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"Once the installation is complete, please turn on the power and perform the initial operation test. The test procedure is explained on page 10 of the manual. If there are any issues with the machine or if you need additional support, please don't hesitate to contact us.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"Thank you, this has been very helpful!\"},\n",
    "    outputs={\n",
    "        \"ai\": \"We're always ready to help. If you have any additional questions or need support, please feel free to ask. Have a great day!\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What should I do after the installation is complete?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Once the installation is complete, please turn on the power and perform the initial operation test. The test procedure is explained on page 10 of the manual. If there are any issues with the machine or if you need additional support, please don't hesitate to contact us.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thank you, this has been very helpful!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"We're always ready to help. If you have any additional questions or need support, please feel free to ask. Have a great day!\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the conversation history\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
