{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {
    "id": "635d8ebb"
   },
   "source": [
    "# JinaReranker\n",
    "## 概述\n",
    "## ```Jina Reranker``` 是一個文件重排序和壓縮工具，重新排序檢索到的文件或結果，以優先顯示最相關的項目。它主要用於資訊檢索和自然語言處理（NLP）任務，旨在從大型資料集中更快、更準確地提取關鍵資訊。\n",
    "\n",
    "---\n",
    "**主要功能**\n",
    "- 基於相關性的重排序\n",
    " Jina Reranker 分析搜尋結果並根據相關性分數重新排序文件。這確保使用者可以優先存取更相關的資訊。\n",
    "- 多語言支援\n",
    " Jina Reranker 支援多語言模型，如 ```jina-reranker-v2-base-multilingual```，能夠處理各種語言的資料。\n",
    "- 文件壓縮\n",
    " 它只選擇前 N 個最相關的文件（```top_n```），壓縮搜尋結果以減少噪音並優化效能。\n",
    "- 與 LangChain 整合\n",
    " Jina Reranker 與 LangChain 等工作流程工具無縫整合，便於連接到自然語言處理管道。\n",
    "\n",
    "---\n",
    "**運作方式**\n",
    "- 文件檢索\n",
    " 使用基礎檢索器擷取初始搜尋結果。\n",
    "- 相關性分數計算\n",
    " Jina Reranker 利用預訓練模型（如 ```jina-reranker-v2-base-multilingual```）計算每個文件的相關性分數。\n",
    "- 文件重排序和壓縮\n",
    " 基於相關性分數，選擇前 N 個文件並提供重新排序的結果。\n",
    "\n",
    "### 目錄\n",
    "- [概述](#概述)\n",
    "- [環境設定](#環境設定)\n",
    "- [Jina Reranker](#jina-reranker)\n",
    "- [使用 JinaRerank 執行重排序](#使用jinarerank執行重排序)\n",
    "\n",
    "### 參考資料\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/how_to/lcel_cheatsheet/)\n",
    "- [Jina Reranker](https://jina.ai/reranker/)\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "Jina Reranker 提供了企業級的重排序解決方案，特別在多語言支援和 LangChain 整合方面表現出色，適合國際化應用需求。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**技術特色：**\n",
    "- **多語言優勢**：支援跨語言檢索和排序\n",
    "- **企業級穩定性**：Jina AI 提供的商業級服務\n",
    "- **高效壓縮**：智能選擇最相關文件減少噪音\n",
    "- **API 整合**：雲端服務易於部署和擴展\n",
    "\n",
    "**與其他重排器比較：**\n",
    "- **vs CrossEncoder**：更易使用，無需本地模型部署\n",
    "- **vs 開源方案**：更好的多語言支援和穩定性\n",
    "- **vs 自建方案**：減少維護成本，專業優化\n",
    "\n",
    "**適用場景：**\n",
    "- **國際化應用**：需要處理多種語言的搜尋系統\n",
    "- **企業知識庫**：大規模文檔的精確檢索\n",
    "- **電商平台**：多語言商品搜尋和推薦\n",
    "- **客服系統**：跨語言的智能問答\n",
    "\n",
    "**部署考量：**\n",
    "- **API 限制**：注意請求頻率和資料量限制\n",
    "- **成本控制**：根據使用量優化成本\n",
    "- **延遲管理**：網路請求可能增加響應時間\n",
    "- **備用方案**：考慮本地重排器作為降級選項"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {
    "id": "c6c7aba4"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n",
    "**Issuing an API Key for JinaReranker**\n",
    "- Add the following to your .env file\n",
    "    >JINA_API_KEY=\"YOUR_JINA_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21943adb",
   "metadata": {
    "id": "21943adb"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ec196",
   "metadata": {
    "id": "f25ec196"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a9ae0",
   "metadata": {
    "id": "690a9ae0"
   },
   "source": [
    "You can also load the ```OPEN_API_KEY``` from the ```.env``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f99b5b6",
   "metadata": {
    "id": "4f99b5b6",
    "outputId": "e9c746f6-9379-4063-a1e9-6f743c1accd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9065ea",
   "metadata": {
    "id": "7f9065ea",
    "outputId": "24b5c7e9-915f-4e66-8b99-d550efea277f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set local environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"03-JinaReranker\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {
    "id": "aa00c3f4"
   },
   "source": [
    "## Jina Reranker\n",
    "\n",
    "- Load data for a simple example and create a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cb77da",
   "metadata": {
    "id": "69cb77da"
   },
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74660e4d",
   "metadata": {
    "id": "74660e4d"
   },
   "source": [
    "- A text document is loaded into the system.\n",
    "\n",
    "- The document is split into smaller chunks for better processing.\n",
    "\n",
    "- ```FAISS``` is used with ```OpenAI embeddings``` to create a retriever.\n",
    "\n",
    "- The retriever processes a query to find and display the most relevant documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d367787",
   "metadata": {
    "id": "3d367787",
    "outputId": "ec8c5a24-c194-48d6-ba67-4b0cbc6462d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Word2Vec\n",
      "Definition: Word2Vec is a technique in NLP that maps words to a vector space, representing their semantic relationships based on context.\n",
      "Example: In a Word2Vec model, \"king\" and \"queen\" are represented by vectors located close to each other.\n",
      "Related Keywords: Natural Language Processing (NLP), Embedding, Semantic Similarity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Embedding\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors that computers can process and understand.\n",
      "Example: The word \"apple\" can be represented as a vector like [0.65, -0.23, 0.17].\n",
      "Related Keywords: Natural Language Processing (NLP), Vectorization, Deep Learning\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "VectorStore\n",
      "Definition: A VectorStore is a system designed to store data in vector format, enabling efficient retrieval, classification, and analysis tasks.\n",
      "Example: Storing word embedding vectors in a database for quick access during semantic search.\n",
      "Related Keywords: Embedding, Database, Vectorization\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
      "Definition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document by considering its frequency and rarity across a corpus.\n",
      "Example: Words with high TF-IDF values are often unique and critical for understanding the document.\n",
      "Related Keywords: Natural Language Processing (NLP), Information Retrieval, Data Mining\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "GPT (Generative Pretrained Transformer)\n",
      "Definition: GPT is a generative language model pre-trained on vast datasets, capable of performing various text-based tasks. It generates natural and coherent text based on input.\n",
      "Example: A chatbot generating detailed answers to user queries is powered by GPT models.\n",
      "Related Keywords: Natural Language Processing (NLP), Text Generation, Deep Learning\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "Tokenizer\n",
      "Definition: A tokenizer is a tool that splits text data into tokens, often used for preprocessing in natural language processing tasks.\n",
      "Example: The sentence \"I love programming.\" is tokenized into [\"I\", \"love\", \"programming\", \".\"].\n",
      "Related Keywords: Tokenization, Natural Language Processing (NLP), Syntax Analysis.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      "LLM (Large Language Model)\n",
      "Definition: LLMs are massive language models trained on large-scale text data, used for various natural language understanding and generation tasks.\n",
      "Example: OpenAI's GPT series is a prominent example of LLMs.\n",
      "Related Keywords: Natural Language Processing (NLP), Deep Learning, Text Generation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      "Transformer\n",
      "Definition: A Transformer is a type of deep learning model widely used in natural language processing tasks like translation, summarization, and text generation. It is based on the Attention mechanism.\n",
      "Example: Google Translate utilizes a Transformer model for multilingual translation.\n",
      "Related Keywords: Deep Learning, Natural Language Processing (NLP), Attention mechanism\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      "Semantic Search\n",
      "Definition: Semantic search is a search technique that understands the meaning of a user's query beyond simple keyword matching, returning results that are contextually relevant.\n",
      "Example: If a user searches for \"planets in the solar system,\" the system provides information about planets like Jupiter and Mars.\n",
      "Related Keywords: Natural Language Processing (NLP), Search Algorithms, Data Mining\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      "HuggingFace\n",
      "Definition: HuggingFace is a library offering pre-trained models and tools for natural language processing, making NLP tasks accessible to researchers and developers.\n",
      "Example: HuggingFace's Transformers library can be used for sentiment analysis and text generation.\n",
      "Related Keywords: Natural Language Processing (NLP), Deep Learning, Library.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load the document\n",
    "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "# Split the document into chunks\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "\n",
    "# Define the query\n",
    "query = \"Tell me about Word2Vec.\"\n",
    "\n",
    "# Retrieve relevant documents\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "# Print the retrieved documents\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac736fc2",
   "metadata": {
    "id": "ac736fc2"
   },
   "source": [
    "## 使用 JinaRerank 執行重排序\n",
    "- 使用 JinaRerank 初始化文件壓縮系統，以優先處理最相關的文件。\n",
    "- 透過選擇前 3 個最相關的文件（top_n=3）來壓縮檢索文件。\n",
    "- 使用 JinaRerank 壓縮器和現有檢索器建立 ```ContextualCompressionRetriever```。\n",
    "- 系統處理查詢以檢索和壓縮相關文件。\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "這個實作展示了 JinaRerank 的核心工作流程，透過簡潔的配置就能實現高效的文件重排序和壓縮。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**實作要點：**\n",
    "- **top_n 參數**：控制最終保留的文件數量\n",
    "- **壓縮策略**：結合重排序和數量限制\n",
    "- **無縫整合**：與現有檢索器完美配合\n",
    "- **查詢處理**：自動化的相關性評估流程\n",
    "\n",
    "**配置建議：**\n",
    "- **top_n=3**：適合問答系統的精確回答\n",
    "- **top_n=5-10**：適合需要更多上下文的場景\n",
    "- **動態調整**：根據查詢複雜度調整數量\n",
    "\n",
    "**效能優化：**\n",
    "- 減少無關文件干擾\n",
    "- 降低後續處理成本\n",
    "- 提升生成內容品質\n",
    "- 改善用戶體驗\n",
    "\n",
    "**監控指標：**\n",
    "- 重排序準確率\n",
    "- 響應時間變化\n",
    "- 文件壓縮比例\n",
    "- 最終答案品質"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2b5c5",
   "metadata": {
    "id": "f4a2b5c5"
   },
   "outputs": [],
   "source": [
    "from ast import mod\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_compressors import JinaRerank\n",
    "\n",
    "# Initialize the JinaRerank compressor\n",
    "compressor = JinaRerank(model=\"jina-reranker-v2-base-multilingual\", top_n=3)\n",
    "\n",
    "# Initialize the document compression retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# Retrieve and compress relevant documents\n",
    "compressed_docs = compression_retriever.invoke(\"Explain Word2Vec.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b93e0a5",
   "metadata": {
    "id": "3b93e0a5",
    "outputId": "c91947f7-f275-4acf-86d0-914eebcbf373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Word2Vec\n",
      "Definition: Word2Vec is a technique in NLP that maps words to a vector space, representing their semantic relationships based on context.\n",
      "Example: In a Word2Vec model, \"king\" and \"queen\" are represented by vectors located close to each other.\n",
      "Related Keywords: Natural Language Processing (NLP), Embedding, Semantic Similarity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Embedding\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors that computers can process and understand.\n",
      "Example: The word \"apple\" can be represented as a vector like [0.65, -0.23, 0.17].\n",
      "Related Keywords: Natural Language Processing (NLP), Vectorization, Deep Learning\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "VectorStore\n",
      "Definition: A VectorStore is a system designed to store data in vector format, enabling efficient retrieval, classification, and analysis tasks.\n",
      "Example: Storing word embedding vectors in a database for quick access during semantic search.\n",
      "Related Keywords: Embedding, Database, Vectorization\n"
     ]
    }
   ],
   "source": [
    "# Display the compressed documents in a readable format\n",
    "pretty_print_docs(compressed_docs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
