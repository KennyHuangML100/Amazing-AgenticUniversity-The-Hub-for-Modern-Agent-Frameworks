{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 第 3 章 有記憶的簡易聊天程式–串接記錄與串流回應"
      ],
      "metadata": {
        "id": "sJzEuUP6Zhm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-1 文字形式的簡易聊天程式"
      ],
      "metadata": {
        "id": "8W6rYxSbZv2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "先匯入必要的模組並建立客戶端："
      ],
      "metadata": {
        "id": "Cs4wTWDwZoIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUqfGpzylQ_Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from IPython.display import display, Markdown\n",
        "from rich.pretty import pprint\n",
        "import sys\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "IEb6ydrt362e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立輔助函式與聊天程式雛形"
      ],
      "metadata": {
        "id": "lZtPSMxsOjWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reply_text(msg):\n",
        "    try:\n",
        "        response = client.responses.create(\n",
        "            instructions='使用繁體中文',\n",
        "            model=\"gpt-4.1-nano\",\n",
        "            input=msg\n",
        "        )\n",
        "        return response.output_text\n",
        "    except openai.APIError as err:\n",
        "        print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "        return ''"
      ],
      "metadata": {
        "id": "cKgPwG4klZFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"直接按 ↵ 可結束對話\")\n",
        "while True:\n",
        "    msg = input(\">>> \")\n",
        "    if not msg.strip(): break # 直接 ↵ 就結束\n",
        "    reply = get_reply_text(msg)\n",
        "    display(Markdown(f'{reply}'))"
      ],
      "metadata": {
        "id": "chIxIAiWlqO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2 串接對話記錄"
      ],
      "metadata": {
        "id": "Oya0_5_EaAcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用回應識別碼提供對談內容"
      ],
      "metadata": {
        "id": "Y_OzRRwUQFiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    instructions='使用繁體中文',\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"你知道什麼是流冰嗎？\",\n",
        ")\n",
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "bG6m7TU4oVT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = client.responses.create(\n",
        "    instructions='使用繁體中文',\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"哪裡看得到？\",\n",
        ")\n",
        "display(Markdown(response1.output_text))"
      ],
      "metadata": {
        "id": "VJeMiEZHrV97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = client.responses.create(\n",
        "    instructions='使用繁體中文',\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"哪裡看得到？\",\n",
        "    # 串接訊息\n",
        "    previous_response_id=response.id,\n",
        ")\n",
        "display(Markdown(response2.output_text))"
      ],
      "metadata": {
        "id": "4rLs9m65rjqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response1.usage)\n",
        "pprint(response2.usage)"
      ],
      "metadata": {
        "id": "j_tauav8R6-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.id)\n",
        "print(response1.previous_response_id)\n",
        "print(response2.previous_response_id)"
      ],
      "metadata": {
        "id": "h0Lq5uGbSeAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 強制不儲存回應"
      ],
      "metadata": {
        "id": "6ibr6e-0SX10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    instructions='使用繁體中文',\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"你知道什麼是流冰嗎？\",\n",
        "    store=False # 控制是否儲存回應\n",
        ")\n",
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "-2yHmTUs3-Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    instructions='使用繁體中文',\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"哪裡看得到？\",\n",
        "    # 串接沒儲存的訊息會出錯\n",
        "    previous_response_id=response.id,\n",
        ")"
      ],
      "metadata": {
        "id": "eIZOW4Uh4Mkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 控制串接的輸入內容"
      ],
      "metadata": {
        "id": "83k8hZh1TC3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 幫聊天輔助函式串接對話過程"
      ],
      "metadata": {
        "id": "Hu42Zu4qTmDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client):\n",
        "        self._last_id = None   # 紀錄最後回憶的識別碼\n",
        "        self._client = client  # 叫用 API 的用戶端\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop(\n",
        "            'instructions', '使用繁體中文'\n",
        "        )\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=msg,\n",
        "                previous_response_id=self._last_id, # 串接回應\n",
        "                **kwargs\n",
        "            )\n",
        "            self._last_id = response.id # 更新回應識別碼\n",
        "            return response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(\n",
        "                f'Error:{err.body[\"message\"]}',\n",
        "                file=sys.stderr\n",
        "            )\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(\">>> \")\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            reply = self.get_reply_text(user_msg, **kwargs)\n",
        "            display(Markdown(f'{reply}'))"
      ],
      "metadata": {
        "id": "F0Eq3B7m9h-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chat(client).loop()"
      ],
      "metadata": {
        "id": "UWThHPvqy8qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3 使用串流功能即時顯示回覆內容"
      ],
      "metadata": {
        "id": "qDbNOQ04aL1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 啟用串流功能"
      ],
      "metadata": {
        "id": "5wt_hSpJVXrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"你好\",\n",
        "    stream=True,\n",
        ")"
      ],
      "metadata": {
        "id": "YsoFxYB63nAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in response:\n",
        "    pprint(event)"
      ],
      "metadata": {
        "id": "ajoE5z_Y3qWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"什麼是 pair programming？\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "text = ''\n",
        "display_handle = display(text, display_id=True)\n",
        "for event in response:\n",
        "    # 篩選事件種類即可取得即時生成的部分內容\n",
        "    if event.type == 'response.output_text.delta':\n",
        "        text += event.delta\n",
        "        display_handle.update(Markdown(text))"
      ],
      "metadata": {
        "id": "4IEdCw3S3ySl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"什麼是 peer review？\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for event in response:\n",
        "    # 最後的事件會有完整的生成內容，不用自己一段一段拼接\n",
        "    if event.type == 'response.completed':\n",
        "        display(Markdown('-' * 20))\n",
        "        display(Markdown(\n",
        "            f'{event.response.output_text}'\n",
        "        ))\n",
        "        display(Markdown('-' * 20))\n",
        "        display(Markdown(\n",
        "            f'{event.response.output[0].content[0].text}'\n",
        "        ))"
      ],
      "metadata": {
        "id": "1k19XgvA6G9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 加入串流選項的聊天類別"
      ],
      "metadata": {
        "id": "C7Dk89NIGpFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, last_id=None):\n",
        "        self._last_id = last_id\n",
        "        self._client = client\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop(\n",
        "            'instructions', '使用繁體中文'\n",
        "        )\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=msg,\n",
        "                stream=True, # 都以串流方式處理，簡化程式邏輯\n",
        "                previous_response_id=self._last_id, # 串接回應\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # 串流模式生成片段內容\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    # 記錄識別碼\n",
        "                    self._last_id = event.response.id\n",
        "                    if not stream: # 非串流生成完整內容\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(\n",
        "                f'Error:{err.body[\"message\"]}',\n",
        "                file=sys.stderr\n",
        "            )\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(\">>> \")\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                **kwargs\n",
        "            ):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))"
      ],
      "metadata": {
        "id": "8QR0Rcx81RKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chat(client).loop()"
      ],
      "metadata": {
        "id": "1Huk9_kx3Gpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1 = Chat(client)\n",
        "chat1.loop(stream=True)"
      ],
      "metadata": {
        "id": "9GR8HWoX3ftf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat2 = Chat(client, last_id=chat1._last_id)\n",
        "chat2.loop(stream=True)"
      ],
      "metadata": {
        "id": "XXJHn5Xb3u0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4 具有記憶的聊天程式"
      ],
      "metadata": {
        "id": "pNkfIZvmafql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 將回應識別碼儲存到檔案以及從檔案讀回的方法"
      ],
      "metadata": {
        "id": "48eTSptyIe7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, last_id=None):\n",
        "        self._last_id = last_id\n",
        "        self._client = client\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', '使用繁體中文')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=msg,\n",
        "                stream=True, # 都以串流方式處理，簡化程式邏輯\n",
        "                previous_response_id=self._last_id, # 串接回應\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # 串流模式生成片段內容\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    self._last_id = event.response.id # 記錄識別碼\n",
        "                    if not stream: # 非串流生成完整內容\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(\">>> \")\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(user_msg, **kwargs):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(self._last_id)\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'r') as f:\n",
        "            self._last_id = f.read()"
      ],
      "metadata": {
        "id": "ipTIXnBdXSb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 可延續討論串交談的應用程式"
      ],
      "metadata": {
        "id": "Vw7e-qcrbaSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat1 = Chat(client)\n",
        "chat1.loop(stream=True)"
      ],
      "metadata": {
        "id": "XskC3hxMmbwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.save('last_id')"
      ],
      "metadata": {
        "id": "Ey2rYznhYhnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat2 = Chat(client)\n",
        "chat2.load('last_id')\n",
        "chat2.loop(stream=True)"
      ],
      "metadata": {
        "id": "O0LAlxEjZOfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 透過網頁檢視儲存的回應"
      ],
      "metadata": {
        "id": "D-nY2wM2ap2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "你也可到 [dashboard 頁面](https://platform.openai.com/logs)查看對話記錄"
      ],
      "metadata": {
        "id": "U4JBHUqlbEwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 利用程式碼管理對談記錄"
      ],
      "metadata": {
        "id": "OYF4YNKTMBeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 依據識別碼取得回應與輸入內容"
      ],
      "metadata": {
        "id": "TyFC19pbMEJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得指定識別碼的回應\n",
        "response = client.responses.retrieve(chat2._last_id)\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "z9hfzV50-W97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得指定識別碼回應的輸入（含對話串）\n",
        "response = client.responses.input_items.list(\n",
        "    chat2._last_id\n",
        ")\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "0Ayw5VG2D2Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 顯示完整討論串"
      ],
      "metadata": {
        "id": "H3bbrJekM_i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 顯示完整對話\n",
        "inputs = client.responses.input_items.list(chat2._last_id)\n",
        "response = client.responses.retrieve(chat2._last_id)\n",
        "for item in inputs.data[::-1]:\n",
        "    prompt = \">>> \" if item.role == 'user' else ''\n",
        "    for content in item.content:\n",
        "        print(f'{prompt}{content.text}')\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "IYFougyOEebp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 刪除討論串"
      ],
      "metadata": {
        "id": "DjULhpUuekbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_id = chat2._last_id\n",
        "while last_id:\n",
        "    response = client.responses.retrieve(last_id)\n",
        "    last_id, curr_id = response.previous_response_id, last_id\n",
        "    client.responses.delete(curr_id)"
      ],
      "metadata": {
        "id": "yqvYKA-abj2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 幫聊天程式加上討論串管理功能"
      ],
      "metadata": {
        "id": "wH6YN-Kd2Xjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, last_id=None):\n",
        "        self._last_id = last_id\n",
        "        self._client = client\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', '使用繁體中文')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=msg,\n",
        "                stream=True, # 都以串流方式處理，簡化程式邏輯\n",
        "                previous_response_id=self._last_id, # 串接回應\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # 串流模式生成片段內容\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    self._last_id = event.response.id # 記錄識別碼\n",
        "                    if not stream: # 非串流生成完整內容\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(\">>> \")\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(user_msg, **kwargs):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(self._last_id)\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'r') as f:\n",
        "            self._last_id = f.read()\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(\n",
        "            self._last_id\n",
        "        )\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ],
      "metadata": {
        "id": "MIIEqWnu2QHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = Chat(client)\n",
        "chat.loop(stream=True)"
      ],
      "metadata": {
        "id": "EAOln2Ba291y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.show_thread()"
      ],
      "metadata": {
        "id": "zTZBdvPm3Rd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.delete_thread()"
      ],
      "metadata": {
        "id": "DLaiRjIW3UNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-5 手動建立對話記錄"
      ],
      "metadata": {
        "id": "wasSGeoEazW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 自行建立對話記錄"
      ],
      "metadata": {
        "id": "KDDUgENPOT9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatWithHistList:\n",
        "    def __init__(self, client):\n",
        "        self._hist = [] # 記錄對話過程\n",
        "        self._client = client\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop(\n",
        "            'instructions', '使用繁體中文'\n",
        "        )\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=self._hist + [{\n",
        "                    'role': 'user', 'content': msg\n",
        "                }],\n",
        "                stream=True, # 都以串流方式處理，簡化程式邏輯\n",
        "                store=False, # 不儲存對話\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # 串流模式生成片段內容\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    # 新增對話\n",
        "                    self._hist += [\n",
        "                        {'role': 'user', 'content': msg},\n",
        "                        {'role': 'assistant',\n",
        "                         'content': event.response.output_text}\n",
        "                    ]\n",
        "                    if not stream: # 非串流生成完整內容\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(\n",
        "                f'Error:{err.body[\"message\"]}',\n",
        "                file=sys.stderr\n",
        "            )\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(\">>> \")\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(user_msg, **kwargs):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))"
      ],
      "metadata": {
        "id": "w2gSIyFFrEx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChatWithHistList(client).loop(stream=True)"
      ],
      "metadata": {
        "id": "bjkVZgBJtLUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 儲存對話記錄"
      ],
      "metadata": {
        "id": "LPZDQVEfa4gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "wAkMTocTJc0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatWithHistList:\n",
        "    def __init__(self, client):\n",
        "        self._hist = [] # 記錄對話過程\n",
        "        self._client = client\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', '使用繁體中文')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=self._hist + [{'role': 'user', 'content': msg}],\n",
        "                stream=True, # 都以串流方式處理，簡化程式邏輯\n",
        "                store=False, # 不儲存對話\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # 串流模式生成片段內容\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    # 新增對話\n",
        "                    self._hist += [\n",
        "                        {'role': 'user', 'content': msg},\n",
        "                        {'role': 'assistant',\n",
        "                         'content': event.response.output_text}\n",
        "                    ]\n",
        "                    if not stream: # 非串流生成完整內容\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(\">>> \")\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(user_msg, **kwargs):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(self._hist, f)\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            self._hist = pickle.load(f)"
      ],
      "metadata": {
        "id": "OXEgoffC1OnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1 = ChatWithHistList(client)\n",
        "chat1.loop(stream=True)"
      ],
      "metadata": {
        "id": "DDQ1j_85W_ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.save('hist.db')"
      ],
      "metadata": {
        "id": "TOnadI0cXOmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat2 = ChatWithHistList(client)\n",
        "chat2.load('hist.db')\n",
        "chat2.loop(stream=True)"
      ],
      "metadata": {
        "id": "a9AKe96gXosg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K51NXug9A_93"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}