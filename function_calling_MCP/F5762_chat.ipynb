{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# F5762 重新架構的 Chat 類別\n",
        "\n",
        "原本的架構要加入新的工具都要修改類別內的程式，目前的架構只要定義新的工具指令類別，就可以加入新的工具，更具彈性，也更容易講解。"
      ],
      "metadata": {
        "id": "K83pFX7OBKB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 匯入通用的模組與建立 OpenAI API 用戶端"
      ],
      "metadata": {
        "id": "mGEIbPSRBhkK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G48WFQgpgaF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from rich.pretty import pprint\n",
        "import openai\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "vW3blDmDpxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第 4 章上傳檔案的輔助函式"
      ],
      "metadata": {
        "id": "utyzVjC4BHz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def upload_file(file_path):\n",
        "    try:\n",
        "        if (file_path.startswith('http://')\n",
        "            or file_path.startswith('https://')):\n",
        "            response = requests.get(file_path)\n",
        "            filename = response.headers.get(\n",
        "                'content-disposition',\n",
        "                None\n",
        "            )\n",
        "            if filename:\n",
        "                filename = filename.split('filename=')[-1]\n",
        "                filename = filename.strip('\\'\"')\n",
        "            else:\n",
        "                filename = file_path.split('/')[-1]\n",
        "            response = client.files.create(\n",
        "                file=(filename, response.content),\n",
        "                purpose='user_data'\n",
        "            )\n",
        "        else:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                response = client.files.create(\n",
        "                    file=file,\n",
        "                    purpose='user_data'\n",
        "                )\n",
        "    except:\n",
        "        return None\n",
        "    return response.id"
      ],
      "metadata": {
        "id": "jROS7uYMp0GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用者指令處理器的類別\n",
        "\n",
        "這是基礎類別，訂定了工具指令類別的基本架構：\n",
        "\n",
        "- handle_command：處理以 '/' 開頭的指令，並依據需要更新 Chat 類別的 tools 工具串列。\n",
        "\n",
        "    如果傳入的指令是空字串，表示是建立 Chat 類別的物件時設定初始值，若需要在物件一建立就更新它的 tools 串列，就要處理空字串指令。\n",
        "- handle_event：處理串列輸出時的個別事件：\n",
        "\n",
        "    - 若還要交給下一個指令處理器，傳回 None\n",
        "    - 傳回訊息串列表示要送回給模型參考再重新生成\n",
        "    - 傳回其他內容都表示要交給 Chat 顯示。"
      ],
      "metadata": {
        "id": "FKctZhnxBwoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseComand:\n",
        "    def __init__(self, command, tool_name, icon, verbose=False):\n",
        "        self.command = command      # 指令\n",
        "        self.tool_name = tool_name  # 工具名稱\n",
        "        self.icon = icon            # 工具圖示字元\n",
        "        self.verbose = verbose      # 啟用詳細輸出\n",
        "        self.extra_args = {}        # 要額外送給模型的參數\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        # 不是正確的指令開頭（空字串會是 True）\n",
        "        if not cmd.startswith(self.command):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        return None # 預設不處理交給下一個指令處理器"
      ],
      "metadata": {
        "id": "UW3h8za7q8ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 內建搜尋工具的指令處理器"
      ],
      "metadata": {
        "id": "wURiB390DvMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import unquote\n",
        "\n",
        "class WebSearchCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/w',\n",
        "            'web_search_preview',\n",
        "            '🌐',\n",
        "            verbose\n",
        "        )\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def show_search_results(self, response):\n",
        "        if response.output[0].type != \"web_search_call\":\n",
        "            return\n",
        "        content = response.output[1].content[0]\n",
        "        for i, annotaion in enumerate(\n",
        "            content.annotations, start=1\n",
        "        ):\n",
        "            print(f'{i}. {annotaion.title}')\n",
        "            print(f'   {unquote(annotaion.url)}')\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "i3MaoFBSsmx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 內建檔案檢索工具的指令處理器"
      ],
      "metadata": {
        "id": "57RVYfK8DzB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FileSearchCommand(BaseComand):\n",
        "    def __init__(self, vector_store_id=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/f',\n",
        "            'file_search',\n",
        "            '🔍',\n",
        "            verbose\n",
        "        )\n",
        "        self.vector_store_id = vector_store_id\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if len(cmd) < 4: # /f[.]，不是冒號加檔名/網址\n",
        "            if self.vector_store_id == None:\n",
        "                print('請先使用 /f:[路徑|網址]上傳檔案')\n",
        "                return True # 沒有向量資料庫無法切換\n",
        "            turn_on = (idx == -1) # 切換開/關檔案檢索\n",
        "        else: # /f:檔名|網址，上傳檔案並開啟檢索功能\n",
        "            turn_on = True\n",
        "            file_path = cmd[3:]\n",
        "            file_id= upload_file(file_path)\n",
        "            if not file_id:\n",
        "                print(f'無法上傳檔案：{file_path}')\n",
        "                return True\n",
        "            if self.vector_store_id == None:\n",
        "                vector_store = client.vector_stores.create(\n",
        "                    name=\"temp\",\n",
        "                    file_ids=[file_id],\n",
        "                )\n",
        "                self.vector_store_id = vector_store.id\n",
        "            else:\n",
        "                client.vector_stores.files.create(\n",
        "                    self.vector_store_id,\n",
        "                    file_id=file_id\n",
        "                )\n",
        "        if turn_on:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'vector_store_ids': [self.vector_store_id]\n",
        "            })\n",
        "            self.extra_args = {\n",
        "                'include': ['file_search_call.results']\n",
        "            }\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "            self.extra_args = {}\n",
        "        return True\n",
        "\n",
        "    def remove_vector_store(self, chat):\n",
        "        if self.vector_store_id == None: return\n",
        "        idx = chat.find_tool_index('file_search')\n",
        "        if idx: chat.tools.pop(idx)\n",
        "        response = client.vector_stores.files.list(\n",
        "            self.vector_store_id\n",
        "        )\n",
        "        for vector_file in response.data:\n",
        "            client.files.delete(vector_file.id)\n",
        "        client.vector_stores.delete(self.vector_store_id)\n",
        "\n",
        "    def show_file_search_results(self, response):\n",
        "        if response.output[0].type != 'file_search_call':\n",
        "            return\n",
        "        results = response.output[0].results\n",
        "        if not results: return\n",
        "        for i, result in enumerate(results, start=1):\n",
        "            display(Markdown('---'))\n",
        "            print(f'{i}. {result.filename}({result.score})')\n",
        "            display(Markdown('---'))\n",
        "            display(Markdown(result.text))\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_file_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "Z_K_AXc_ttpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 內建程式碼直譯器工具的指令處理器"
      ],
      "metadata": {
        "id": "v3AbNkLnD2Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeInterpreterCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/c',\n",
        "            'code_interpreter',\n",
        "            '🐍',\n",
        "            verbose\n",
        "        )\n",
        "\n",
        "    def get_file_content_from_container(\n",
        "            self, container_id, file_id\n",
        "    ):\n",
        "        url = (\n",
        "            'https://api.openai.com/v1/containers/'\n",
        "            f'{container_id}'\n",
        "            '/files/'\n",
        "            f'{file_id}'\n",
        "            '/content'\n",
        "        )\n",
        "        response = requests.get(\n",
        "            url,\n",
        "            headers={\n",
        "                'Authorization': f'Bearer {client.api_key}'\n",
        "            }\n",
        "        )\n",
        "        if response.status_code != 200:\n",
        "            return None\n",
        "        return response.content\n",
        "\n",
        "    def get_code_interpreter_files(self, response):\n",
        "        files = []\n",
        "        for output in response.output:\n",
        "            if output.type != 'message':\n",
        "                continue\n",
        "            for content in output.content:\n",
        "                for annotation in content.annotations:\n",
        "                    if annotation.type != (\n",
        "                        'container_file_citation'\n",
        "                    ):\n",
        "                        continue\n",
        "                    files.append((\n",
        "                        annotation.container_id,\n",
        "                        annotation.file_id,\n",
        "                        annotation.filename\n",
        "                    ))\n",
        "                    content = (\n",
        "                        self.get_file_content_from_container(\n",
        "                        annotation.container_id,\n",
        "                        annotation.file_id\n",
        "                    ))\n",
        "                    if not content:\n",
        "                        print(f'無法下載 {annotation.filename}')\n",
        "                        continue\n",
        "                    with open(annotation.filename, 'wb') as f:\n",
        "                        f.write(content)\n",
        "        return files\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        file_ids = []\n",
        "        if len(cmd) > 3:\n",
        "            file_id= upload_file(cmd[3:])\n",
        "            if not file_id:\n",
        "                print(f'無法上傳檔案：{file_path}')\n",
        "                return True\n",
        "            file_ids.append(file_id)\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'container': {\n",
        "                    'type': 'auto',\n",
        "                    'file_ids': file_ids\n",
        "                }\n",
        "            })\n",
        "            self.extra_args = {\n",
        "                'include': ['code_interpreter_call.outputs'],\n",
        "            }\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "            self.extra_args = {}\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if event.type == 'response.completed':\n",
        "            files = self.get_code_interpreter_files(\n",
        "                event.response\n",
        "            )\n",
        "            for f in files:\n",
        "                print(f'已下載：{f[2]}')\n",
        "            return None\n",
        "        if not self.verbose: return None\n",
        "        if event.type == (\n",
        "            'response.code_interpreter_call.'\n",
        "            'in_progress'\n",
        "        ):\n",
        "            if stream: return '\\n```python\\n'\n",
        "        elif event.type == (\n",
        "            'response.'\n",
        "            'code_interpreter_call_code.delta'\n",
        "        ):\n",
        "            if stream: return event.delta\n",
        "        elif event.type == (\n",
        "            'response.'\n",
        "            'code_interpreter_call_code.done'\n",
        "        ):\n",
        "            if stream: return '\\n```\\n\\n'\n",
        "            else: return f'\\n\\n```python\\n{event.code}\\n```\\n\\n'\n",
        "        elif event.type == 'response.output_item.done':\n",
        "            if event.item.type == 'code_interpreter_call':\n",
        "                results = (\n",
        "                    f'\\n結果是：\\n\\n```\\n'\n",
        "                    f'{event.item.outputs[0][\"logs\"]}'\n",
        "                    f'\\n```\\n\\n'\n",
        "                )\n",
        "                return results\n",
        "        return None"
      ],
      "metadata": {
        "id": "Osp43XUyxb9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 內建影像生成工具的指令處理器"
      ],
      "metadata": {
        "id": "8ylcS5O0D9SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import base64\n",
        "\n",
        "class ImageGenerationCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/i',\n",
        "            'image_generation',\n",
        "            '🎨',\n",
        "            verbose=verbose,\n",
        "        )\n",
        "\n",
        "    def get_img_b64(self, outputs):\n",
        "        img_data = [\n",
        "            output.result for output in outputs\n",
        "            if output.type == 'image_generation_call'\n",
        "        ]\n",
        "        return img_data[0] if img_data else None\n",
        "\n",
        "    def get_img_obj(self, img_b64, width=300):\n",
        "        return Image(base64.b64decode(img_b64), width=width)\n",
        "\n",
        "    def save_img(self, img_b64, filename='gen.png'):\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(base64.b64decode(img_b64))\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'partial_images': 3 if self.verbose else 1\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if event.type == 'response.completed':\n",
        "            b64_data = self.get_img_b64(event.response.output)\n",
        "            if not b64_data: return None\n",
        "        elif event.type == (\n",
        "            'response.image_generation_call.partial_image'\n",
        "        ):\n",
        "            b64_data = event.partial_image_b64\n",
        "        else: return None\n",
        "        return self.get_img_obj(b64_data)"
      ],
      "metadata": {
        "id": "Ko04oT8hzT_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### functional calling 的指令處理器"
      ],
      "metadata": {
        "id": "Pi1RNIiFECvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field, ConfigDict\n",
        "import subprocess\n",
        "\n",
        "def shell_helper(dangerous, shell_command):\n",
        "\n",
        "    if dangerous:\n",
        "        return '指令不安全，無法執行'\n",
        "\n",
        "    # 啟動子行程\n",
        "    process = subprocess.Popen(\n",
        "        shell_command,\n",
        "        shell=True,             # 在 shell 中執行\n",
        "        stdout=subprocess.PIPE, # 擷取標準輸出\n",
        "        stderr=subprocess.PIPE, # 擷取錯誤輸出\n",
        "        text=True               # 以文字形式返回\n",
        "    )\n",
        "\n",
        "    result = '執行結果：\\n\\n```\\n'\n",
        "\n",
        "    # 即時讀取輸出\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        # 如果沒有輸出且行程結束\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            result += output\n",
        "\n",
        "    result += \"```\"\n",
        "\n",
        "    # 檢查錯誤輸出\n",
        "    error = process.stderr.read()\n",
        "    if error:\n",
        "        result += f\"\\n\\n錯誤: {error}\"\n",
        "\n",
        "    # 等待行程結束並取得返回碼\n",
        "    return_code = process.wait()\n",
        "    result += f\"\\n\\n命令執行完成，返回碼: {return_code}\\n\\n\"\n",
        "    return result\n",
        "\n",
        "class ShellHelper(BaseModel):\n",
        "    dangerous: bool = Field(\n",
        "        description='要執行的 shell 指令是否具有危險性？'\n",
        "    )\n",
        "    shell_command: str = Field(\n",
        "        description='要執行的 shell 指令'\n",
        "    )\n",
        "\n",
        "shell_helper_tool = {\n",
        "    'type': 'function',\n",
        "    \"name\": \"shell_helper\",\n",
        "    \"description\": \"我可以執行 shell 指令操控電腦\",\n",
        "    \"parameters\": ShellHelper.model_json_schema(),\n",
        "}"
      ],
      "metadata": {
        "id": "8TJpkSUE743z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class FunctionCallingCommand(BaseComand):\n",
        "    def __init__(self, tools=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/t',\n",
        "            'function',\n",
        "            '',\n",
        "            verbose\n",
        "        )\n",
        "        self.tools = tools or []\n",
        "        self.enabled = False\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        if not self.enabled: # 加入自訂函式工具\n",
        "            chat.tools.extend(self.tools)\n",
        "        else: # 移除自訂工具函式\n",
        "            chat.tools = [\n",
        "                tool for tool in chat.tools\n",
        "                if tool['type'] != self.tool_name\n",
        "            ]\n",
        "        self.enabled = not self.enabled\n",
        "        return True\n",
        "\n",
        "    # 叫用單一函式並且將函式執行結果組成訊息後傳回\n",
        "    def make_tool_msg(self, tool_call):\n",
        "        tool_info = f'{tool_call.name}(**{tool_call.arguments})'\n",
        "        if self.verbose: print(f'叫用：{tool_info}')\n",
        "        func = eval(tool_call.name)\n",
        "        args = json.loads(tool_call.arguments)\n",
        "        result = func(**args)\n",
        "        return {   # 建立可傳回函式執行結果的字典\n",
        "            \"type\": \"function_call_output\", # 以工具角色送出回覆\n",
        "            \"call_id\": tool_call.call_id, # 叫用函式的識別碼\n",
        "            \"output\": result # 函式傳回值\n",
        "        }\n",
        "\n",
        "    def call_tools(self, tool_calls):\n",
        "        msgs = []\n",
        "        for tool_call in tool_calls:\n",
        "            if tool_call.type == 'function_call':\n",
        "                msgs.append(self.make_tool_msg(tool_call))\n",
        "        return msgs if msgs else None\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.enabled: return None\n",
        "        if event.type != 'response.completed':\n",
        "            return None\n",
        "        # 呼叫函式\n",
        "        tool_calls = event.response.output\n",
        "        tool_results = self.call_tools(tool_calls)\n",
        "        if tool_results: return tool_calls + tool_results\n",
        "        return None"
      ],
      "metadata": {
        "id": "I5ygH_nd8Ic8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 搭配指令處理器的 Chat 類別"
      ],
      "metadata": {
        "id": "lDg4Fi3SEQh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "class Chat:\n",
        "    def __init__(self, client, **kwargs):\n",
        "        self._client = client\n",
        "        self._last_id = kwargs.pop('last_id', None)\n",
        "        # 限制工具執行圈數，避免無窮盡叫用工具\n",
        "        self._max_tools_rounds = kwargs.pop('max_tools_rounds', 4)\n",
        "        self.tools = [] # 預設沒有使用工具\n",
        "        self._commands = kwargs.pop('commands', [])\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', '使用繁體中文')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        tool_results = [] # 函式叫用的相關資訊\n",
        "        for command in self._commands:\n",
        "            extra_args = {\n",
        "                k: kwargs[k] + command.extra_args[k]\n",
        "                if k in kwargs\n",
        "                else command.extra_args[k]\n",
        "                for k in command.extra_args\n",
        "            }\n",
        "            kwargs.update(extra_args)\n",
        "        try:\n",
        "            messages = [{'role': 'user', 'content': msg}]\n",
        "            for _ in range(self._max_tools_rounds):\n",
        "                # 方便稍後串接函式叫用資訊\n",
        "                if tool_results: # 串接叫用函式的資訊\n",
        "                    messages += tool_results\n",
        "                response = self._client.responses.create(\n",
        "                    instructions=instructions,\n",
        "                    model=model,\n",
        "                    input=messages,\n",
        "                    stream=True, # 都以串流方式處理，簡化程式邏輯\n",
        "                    previous_response_id=self._last_id, # 串接回應\n",
        "                    **kwargs\n",
        "                )\n",
        "                for event in response:\n",
        "                    for command in self._commands:\n",
        "                        result = command.handle_event(\n",
        "                            self, stream, event\n",
        "                        )\n",
        "                        if result: break\n",
        "                    tool_results = []\n",
        "                    if isinstance(result, list):\n",
        "                        # 工具要送回給模型的訊息串列\n",
        "                        tool_results = result\n",
        "                        break\n",
        "                    elif result: # 指令處理器產生的內容\n",
        "                        yield result\n",
        "                    if event.type == 'response.output_text.delta':\n",
        "                        if stream: yield event.delta\n",
        "                    elif event.type == (\n",
        "                        'response.output_text.done'\n",
        "                    ):\n",
        "                        # 非串流模式要傳回完整內容\n",
        "                        if not stream:\n",
        "                            yield event.text\n",
        "                    elif event.type == 'response.completed':\n",
        "                        # 更新最後回應的識別碼\n",
        "                        self._last_id = event.response.id\n",
        "                if not tool_results:\n",
        "                    # 沒有要送回給模型的訊息\n",
        "                    # 表示已經成功生成內容\n",
        "                    break\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def find_tool_index(self, tool_type):\n",
        "        for i, tool in enumerate(self.tools):\n",
        "            if tool['type'] == tool_type: return i\n",
        "        return -1\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        prompt = ''\n",
        "        for command in self._commands:\n",
        "            idx = self.find_tool_index(command.tool_name)\n",
        "            if idx != -1:\n",
        "                prompt += f'{command.icon}'\n",
        "        user_tools_count = len(self.tools) - len(prompt)\n",
        "        prompt += f'(🛠️{user_tools_count})>>> '\n",
        "        return prompt\n",
        "\n",
        "    def _process_command(self, cmd):\n",
        "        for command in self._commands:\n",
        "            if command.handle_command(self, cmd):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"直接按 ↵ 可結束對話\")\n",
        "        while True:\n",
        "            user_msg = input(self._get_prompt())\n",
        "            if not user_msg.strip(): break # 直接 ↵ 就結束\n",
        "            if self._process_command(user_msg):\n",
        "                continue # 指令不需回覆，回頭讓使用者輸入\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            display_extra_handle = None\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                tools=self.tools, # 傳入要使用的工具\n",
        "                **kwargs\n",
        "            ):\n",
        "                if not isinstance(reply, str):\n",
        "                    if not display_extra_handle:\n",
        "                        display_extra_handle = display(\n",
        "                            reply, display_id=True\n",
        "                        )\n",
        "                    else:\n",
        "                        display_extra_handle.update(reply)\n",
        "                    continue\n",
        "                text += reply\n",
        "                if os.path.exists(text):\n",
        "                    display_handle.update(Markdown(f' text'))\n",
        "                else:\n",
        "                    display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'last_id': self._last_id,\n",
        "                    'tools': self.tools,\n",
        "                    'commands': self._commands\n",
        "                },\n",
        "                f\n",
        "            )\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._last_id = data['last_id']\n",
        "            self.tools = data['tools']\n",
        "            self._commands = data['commands']\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(self._last_id)\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            # 略過函式叫用指示等非訊息內容\n",
        "            if item.type != 'message': continue\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ],
      "metadata": {
        "id": "dOXv8yRiplu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 測試工具與聊天"
      ],
      "metadata": {
        "id": "ksXNIemIEWZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "commands = [\n",
        "    WebSearchCommand(verbose=True),\n",
        "    FileSearchCommand(),\n",
        "    CodeInterpreterCommand(),\n",
        "    ImageGenerationCommand(),\n",
        "    FunctionCallingCommand(\n",
        "        [shell_helper_tool],\n",
        "        verbose=True\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "11dW7i0-6TRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = Chat(\n",
        "    client,\n",
        "    commands=commands,\n",
        ")"
      ],
      "metadata": {
        "id": "VYWClROy6XGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "xgKXPNP_6ZsN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "d4076846-f63b-48d9-aa00-b69763b0bae9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 測試儲存與還原"
      ],
      "metadata": {
        "id": "SR0KAMdvE39_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat.save('chat.pkl')"
      ],
      "metadata": {
        "id": "82y9jk3XwKEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1 = Chat(client)"
      ],
      "metadata": {
        "id": "oqb8kbwQQr-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.load('chat.pkl')"
      ],
      "metadata": {
        "id": "QqrXa3SiRS4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "CfU3DGcYRXjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe27e91-0304-473a-cea9-b4d412e34bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "直接按 ↵ 可結束對話\n",
            "🎨(🛠️0)>>> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 測試移除向量儲存區"
      ],
      "metadata": {
        "id": "qCvC63-vFCx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FileSearchCommand.remove_vector_store(chat)"
      ],
      "metadata": {
        "id": "OVu9vnxrgNMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 測試顯示及移除討論串"
      ],
      "metadata": {
        "id": "vm1mVOv6FGim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.show_thread()"
      ],
      "metadata": {
        "id": "3Tu19ICdRdN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.delete_thread()"
      ],
      "metadata": {
        "id": "pyiYecBc7-CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LESmekHJ_uMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}